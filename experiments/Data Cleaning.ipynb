{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import - Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import calendar\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import - Data Files & Additional Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\bhava\\Downloads\\Re__Capstone_Project__Preliminary_Discussion\\Reviews\\Raw Files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df= pd.read_csv(r'combinedReviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_locations_df=pd.read_csv(r'C:\\Users\\bhava\\Downloads\\Re__Capstone_Project__Preliminary_Discussion\\Reviews\\Mapping Files\\Major Locations.csv')\n",
    "locations_mapping_df=pd.read_csv(r'C:\\Users\\bhava\\Downloads\\Re__Capstone_Project__Preliminary_Discussion\\Reviews\\Mapping Files\\Location Mapping.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_jobFunction(jobFunction):\n",
    "    try:\n",
    "        clean_jobFunc=jobFunction.split(' for ')[0]\n",
    "        return clean_jobFunc\n",
    "    except:\n",
    "        return jobFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_experience(jobFunction):\n",
    "    try:\n",
    "        exp=jobFunction.split(' for ')[1].split(' in ')[0].split(' ')[0]\n",
    "        return exp\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location(jobFunction):\n",
    "    try:\n",
    "        loc=jobFunction.split(' for ')[1].split(' in ')[1]\n",
    "        return loc\n",
    "    except:\n",
    "        return 'Not Specified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_location(location_name):\n",
    "    for loc in major_locations:\n",
    "        ind=-1\n",
    "        if location_name.find(loc)!=-1:\n",
    "            ind=location_name.find(loc)\n",
    "            return loc\n",
    "    if ind==-1:\n",
    "        return location_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_exp_unit(jobFunction):\n",
    "    try:\n",
    "        if jobFunction.split(' for ')[1].split(' in ')[0].find('year')!=-1:\n",
    "            return 12\n",
    "        elif jobFunction.split(' for ')[1].split(' in ')[0].find('month')!=-1:\n",
    "            return 1\n",
    "    except:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Major Locations\n",
    "major_locations=major_locations_df['Major Locations'].to_list()\n",
    "#Dictionary of Locations to be mapped\n",
    "location_mapping=locations_mapping_df.set_index('Original Value')['Mapped Value'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume of Data : (97097, 16)\n"
     ]
    }
   ],
   "source": [
    "print('Volume of Data :',raw_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Data Types:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "skillDevelopment    float64\n",
       "reviewText           object\n",
       "location             object\n",
       "cons                 object\n",
       "salaryBenefits      float64\n",
       "workLifeBalance     float64\n",
       "pros                 object\n",
       "workSatisfaction    float64\n",
       "postedon             object\n",
       "jobSecurity         float64\n",
       "careerGrowth        float64\n",
       "companyCulture      float64\n",
       "company              object\n",
       "jobFunction          object\n",
       "overallScore        float64\n",
       "file                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Column Data Types:')\n",
    "raw_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nulls in each column:\n",
      "skillDevelopment  : 91\n",
      "reviewText  : 53875\n",
      "location  : 30584\n",
      "cons  : 11166\n",
      "salaryBenefits  : 646\n",
      "workLifeBalance  : 89\n",
      "pros  : 6667\n",
      "workSatisfaction  : 643\n",
      "postedon  : 1\n",
      "jobSecurity  : 633\n",
      "careerGrowth  : 651\n",
      "companyCulture  : 624\n",
      "company  : 1\n",
      "jobFunction  : 200\n",
      "overallScore  : 0\n",
      "file  : 0\n"
     ]
    }
   ],
   "source": [
    "print('Number of Nulls in each column:')\n",
    "for col in raw_df.columns:\n",
    "    print(col,' :',raw_df[col].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Expirience and Location from jobFunction column\n",
    "raw_df['extract_location']=raw_df['jobFunction'].apply(lambda x:extract_location(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing Blanks in Location column with data extracted from jobFunction, if available\n",
    "raw_df['cleaned_location']=np.where(raw_df['location'].isna(),raw_df['extract_location'],raw_df['location'])\n",
    "#Imputing unknown locations with Not Specified\n",
    "raw_df['cleaned_location']=raw_df['cleaned_location'].fillna('Not Specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting location city from location columns\n",
    "raw_df['cleaned_location']=raw_df['cleaned_location'].apply(lambda x:clean_location(str(x)))\n",
    "#Harmonizing Locations\n",
    "raw_df['cleaned_location']=raw_df['cleaned_location'].map(location_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bucketing all last 10% of the locations into 'Others'\n",
    "major_locations.append('Not Specified')\n",
    "raw_df['cleaned_location']=np.where(raw_df['cleaned_location'].isin(major_locations),raw_df['cleaned_location'],'Others')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['clean_jobFunc']=raw_df['jobFunction'].apply(lambda x:clean_jobFunction(x))\n",
    "raw_df['experience']=raw_df['jobFunction'].apply(lambda x:extract_experience(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['experience_unit']=raw_df['jobFunction'].apply(lambda x:extract_exp_unit(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_df=raw_df.drop(columns={'experience_unit'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.to_csv(r'C:\\Users\\bhava\\Downloads\\Re__Capstone_Project__Preliminary_Discussion\\Reviews\\Intermediate Files\\cleaned_location.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
